{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emmv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "#import plotly.graph_objs as go\n",
    "#init_notebook_mode(connected=True)\n",
    "import eif as iso\n",
    "from functions import load_dataset,calc_percent_NAs, adfuller_test,data_load\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from emmv import emmv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Flow</th>\n",
       "      <th>P_1</th>\n",
       "      <th>P_3</th>\n",
       "      <th>P_4</th>\n",
       "      <th>P_5</th>\n",
       "      <th>T_2</th>\n",
       "      <th>T_3</th>\n",
       "      <th>T_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:00</th>\n",
       "      <td>47020.962524</td>\n",
       "      <td>2.083591</td>\n",
       "      <td>2.207742</td>\n",
       "      <td>1.494308</td>\n",
       "      <td>1.014526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.092529</td>\n",
       "      <td>22.924228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:01</th>\n",
       "      <td>46970.432281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.207284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014297</td>\n",
       "      <td>23.006652</td>\n",
       "      <td>23.098698</td>\n",
       "      <td>22.922855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:02</th>\n",
       "      <td>46931.465149</td>\n",
       "      <td>2.083860</td>\n",
       "      <td>2.207056</td>\n",
       "      <td>1.493851</td>\n",
       "      <td>1.014069</td>\n",
       "      <td>23.012825</td>\n",
       "      <td>23.106237</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:03</th>\n",
       "      <td>46941.994858</td>\n",
       "      <td>2.084130</td>\n",
       "      <td>2.207513</td>\n",
       "      <td>1.494308</td>\n",
       "      <td>1.014526</td>\n",
       "      <td>23.013511</td>\n",
       "      <td>23.102810</td>\n",
       "      <td>22.915990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:04</th>\n",
       "      <td>47028.034973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.206827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.090473</td>\n",
       "      <td>22.912557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:55</th>\n",
       "      <td>46302.044678</td>\n",
       "      <td>1.978631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.011100</td>\n",
       "      <td>27.887662</td>\n",
       "      <td>27.969157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:56</th>\n",
       "      <td>46220.790482</td>\n",
       "      <td>1.977286</td>\n",
       "      <td>2.129547</td>\n",
       "      <td>1.477621</td>\n",
       "      <td>1.010415</td>\n",
       "      <td>27.889034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.785660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:57</th>\n",
       "      <td>46267.901230</td>\n",
       "      <td>1.977016</td>\n",
       "      <td>2.129318</td>\n",
       "      <td>1.477164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.888348</td>\n",
       "      <td>27.969842</td>\n",
       "      <td>27.793899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:58</th>\n",
       "      <td>46238.770294</td>\n",
       "      <td>1.977824</td>\n",
       "      <td>2.130004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.793212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:59</th>\n",
       "      <td>46308.694839</td>\n",
       "      <td>1.978093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.477392</td>\n",
       "      <td>1.009501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.976011</td>\n",
       "      <td>27.793899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17198 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name                         Flow       P_1       P_3       P_4       P_5  \\\n",
       "Datetime                                                                    \n",
       "2021-03-11 10:10:00  47020.962524  2.083591  2.207742  1.494308  1.014526   \n",
       "2021-03-11 10:10:01  46970.432281       NaN  2.207284       NaN  1.014297   \n",
       "2021-03-11 10:10:02  46931.465149  2.083860  2.207056  1.493851  1.014069   \n",
       "2021-03-11 10:10:03  46941.994858  2.084130  2.207513  1.494308  1.014526   \n",
       "2021-03-11 10:10:04  47028.034973       NaN  2.206827       NaN  1.014297   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "2021-03-11 14:59:55  46302.044678  1.978631       NaN       NaN  1.011100   \n",
       "2021-03-11 14:59:56  46220.790482  1.977286  2.129547  1.477621  1.010415   \n",
       "2021-03-11 14:59:57  46267.901230  1.977016  2.129318  1.477164       NaN   \n",
       "2021-03-11 14:59:58  46238.770294  1.977824  2.130004       NaN  1.009730   \n",
       "2021-03-11 14:59:59  46308.694839  1.978093       NaN  1.477392  1.009501   \n",
       "\n",
       "name                       T_2        T_3        T_4  \n",
       "Datetime                                              \n",
       "2021-03-11 10:10:00        NaN  23.092529  22.924228  \n",
       "2021-03-11 10:10:01  23.006652  23.098698  22.922855  \n",
       "2021-03-11 10:10:02  23.012825  23.106237        NaN  \n",
       "2021-03-11 10:10:03  23.013511  23.102810  22.915990  \n",
       "2021-03-11 10:10:04        NaN  23.090473  22.912557  \n",
       "...                        ...        ...        ...  \n",
       "2021-03-11 14:59:55  27.887662  27.969157        NaN  \n",
       "2021-03-11 14:59:56  27.889034        NaN  27.785660  \n",
       "2021-03-11 14:59:57  27.888348  27.969842  27.793899  \n",
       "2021-03-11 14:59:58        NaN        NaN  27.793212  \n",
       "2021-03-11 14:59:59        NaN  27.976011  27.793899  \n",
       "\n",
       "[17198 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"anomaly 3.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (17198, 8)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.06\n",
      "[IterativeImputer] Change: 185.21818094469492, scaled tolerance: 47.176522064209 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 0.11\n",
      "[IterativeImputer] Change: 613.121087315142, scaled tolerance: 47.176522064209 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 0.16\n",
      "[IterativeImputer] Change: 367.57762090566433, scaled tolerance: 47.176522064209 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 0.25\n",
      "[IterativeImputer] Change: 240.76327517534, scaled tolerance: 47.176522064209 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 0.30\n",
      "[IterativeImputer] Change: 127.88478513270789, scaled tolerance: 47.176522064209 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 0.34\n",
      "[IterativeImputer] Change: 58.97193661217366, scaled tolerance: 47.176522064209 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 0.38\n",
      "[IterativeImputer] Change: 42.09533167469389, scaled tolerance: 47.176522064209 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Flow</th>\n",
       "      <th>P_1</th>\n",
       "      <th>P_3</th>\n",
       "      <th>P_4</th>\n",
       "      <th>P_5</th>\n",
       "      <th>T_2</th>\n",
       "      <th>T_3</th>\n",
       "      <th>T_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:00+00:00</th>\n",
       "      <td>47020.962524</td>\n",
       "      <td>2.083591</td>\n",
       "      <td>2.207742</td>\n",
       "      <td>1.494308</td>\n",
       "      <td>1.014526</td>\n",
       "      <td>23.026113</td>\n",
       "      <td>23.092529</td>\n",
       "      <td>22.924228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:01+00:00</th>\n",
       "      <td>46970.432281</td>\n",
       "      <td>2.083841</td>\n",
       "      <td>2.207284</td>\n",
       "      <td>1.496476</td>\n",
       "      <td>1.014297</td>\n",
       "      <td>23.006652</td>\n",
       "      <td>23.098698</td>\n",
       "      <td>22.922855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:02+00:00</th>\n",
       "      <td>46931.465149</td>\n",
       "      <td>2.083860</td>\n",
       "      <td>2.207056</td>\n",
       "      <td>1.493851</td>\n",
       "      <td>1.014069</td>\n",
       "      <td>23.012825</td>\n",
       "      <td>23.106237</td>\n",
       "      <td>22.927701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:03+00:00</th>\n",
       "      <td>46941.994858</td>\n",
       "      <td>2.084130</td>\n",
       "      <td>2.207513</td>\n",
       "      <td>1.494308</td>\n",
       "      <td>1.014526</td>\n",
       "      <td>23.013511</td>\n",
       "      <td>23.102810</td>\n",
       "      <td>22.915990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 10:10:04+00:00</th>\n",
       "      <td>47028.034973</td>\n",
       "      <td>2.083255</td>\n",
       "      <td>2.206827</td>\n",
       "      <td>1.495331</td>\n",
       "      <td>1.014297</td>\n",
       "      <td>23.010091</td>\n",
       "      <td>23.090473</td>\n",
       "      <td>22.912557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:55+00:00</th>\n",
       "      <td>46302.044678</td>\n",
       "      <td>1.978631</td>\n",
       "      <td>2.131307</td>\n",
       "      <td>1.479657</td>\n",
       "      <td>1.011100</td>\n",
       "      <td>27.887662</td>\n",
       "      <td>27.969157</td>\n",
       "      <td>27.806044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:56+00:00</th>\n",
       "      <td>46220.790482</td>\n",
       "      <td>1.977286</td>\n",
       "      <td>2.129547</td>\n",
       "      <td>1.477621</td>\n",
       "      <td>1.010415</td>\n",
       "      <td>27.889034</td>\n",
       "      <td>27.948747</td>\n",
       "      <td>27.785660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:57+00:00</th>\n",
       "      <td>46267.901230</td>\n",
       "      <td>1.977016</td>\n",
       "      <td>2.129318</td>\n",
       "      <td>1.477164</td>\n",
       "      <td>1.012492</td>\n",
       "      <td>27.888348</td>\n",
       "      <td>27.969842</td>\n",
       "      <td>27.793899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:58+00:00</th>\n",
       "      <td>46238.770294</td>\n",
       "      <td>1.977824</td>\n",
       "      <td>2.130004</td>\n",
       "      <td>1.475974</td>\n",
       "      <td>1.009730</td>\n",
       "      <td>27.887177</td>\n",
       "      <td>27.948116</td>\n",
       "      <td>27.793212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11 14:59:59+00:00</th>\n",
       "      <td>46308.694839</td>\n",
       "      <td>1.978093</td>\n",
       "      <td>2.130729</td>\n",
       "      <td>1.477392</td>\n",
       "      <td>1.009501</td>\n",
       "      <td>27.912283</td>\n",
       "      <td>27.976011</td>\n",
       "      <td>27.793899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17198 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name                               Flow       P_1       P_3       P_4  \\\n",
       "Datetime                                                                \n",
       "2021-03-11 10:10:00+00:00  47020.962524  2.083591  2.207742  1.494308   \n",
       "2021-03-11 10:10:01+00:00  46970.432281  2.083841  2.207284  1.496476   \n",
       "2021-03-11 10:10:02+00:00  46931.465149  2.083860  2.207056  1.493851   \n",
       "2021-03-11 10:10:03+00:00  46941.994858  2.084130  2.207513  1.494308   \n",
       "2021-03-11 10:10:04+00:00  47028.034973  2.083255  2.206827  1.495331   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2021-03-11 14:59:55+00:00  46302.044678  1.978631  2.131307  1.479657   \n",
       "2021-03-11 14:59:56+00:00  46220.790482  1.977286  2.129547  1.477621   \n",
       "2021-03-11 14:59:57+00:00  46267.901230  1.977016  2.129318  1.477164   \n",
       "2021-03-11 14:59:58+00:00  46238.770294  1.977824  2.130004  1.475974   \n",
       "2021-03-11 14:59:59+00:00  46308.694839  1.978093  2.130729  1.477392   \n",
       "\n",
       "name                            P_5        T_2        T_3        T_4  \n",
       "Datetime                                                              \n",
       "2021-03-11 10:10:00+00:00  1.014526  23.026113  23.092529  22.924228  \n",
       "2021-03-11 10:10:01+00:00  1.014297  23.006652  23.098698  22.922855  \n",
       "2021-03-11 10:10:02+00:00  1.014069  23.012825  23.106237  22.927701  \n",
       "2021-03-11 10:10:03+00:00  1.014526  23.013511  23.102810  22.915990  \n",
       "2021-03-11 10:10:04+00:00  1.014297  23.010091  23.090473  22.912557  \n",
       "...                             ...        ...        ...        ...  \n",
       "2021-03-11 14:59:55+00:00  1.011100  27.887662  27.969157  27.806044  \n",
       "2021-03-11 14:59:56+00:00  1.010415  27.889034  27.948747  27.785660  \n",
       "2021-03-11 14:59:57+00:00  1.012492  27.888348  27.969842  27.793899  \n",
       "2021-03-11 14:59:58+00:00  1.009730  27.887177  27.948116  27.793212  \n",
       "2021-03-11 14:59:59+00:00  1.009501  27.912283  27.976011  27.793899  \n",
       "\n",
       "[17198 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = calc_percent_NAs(data)\n",
    "cols = data.columns\n",
    "index = pd.to_datetime(data.index,utc = True)\n",
    "##Missing values imputation\n",
    "lr = LinearRegression()\n",
    "imp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=10, verbose=2, imputation_order='roman',random_state=0)\n",
    "data = imp.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=cols, index = index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = train_test_split(data, test_size=0.4, shuffle = False,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_score(n_estimators,max_samples,contamination, X):\\n    from sklearn.metrics import silhouette_score\\n    F2 = IsolationForest(n_estimators=n_estimators, max_samples=max_samples, contamination=contamination,                         max_features=1.0, bootstrap=False, n_jobs=-1, verbose=0, random_state = 42)\\n    F2.fit(X)\\n    pred=F2.predict(X)\\n    score = silhouette_score(X, pred)\\n    print(\"n_estimators = \", n_estimators, \", max_samples=\", max_samples,\", contamination= \",contamination, \", score= \", score)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Silhouette Score. Not very successful.\n",
    "\"\"\"def get_score(n_estimators,max_samples,contamination, X):\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    F2 = IsolationForest(n_estimators=n_estimators, max_samples=max_samples, contamination=contamination, \\\n",
    "                        max_features=1.0, bootstrap=False, n_jobs=-1, verbose=0, random_state = 42)\n",
    "    F2.fit(X)\n",
    "    pred=F2.predict(X)\n",
    "    score = silhouette_score(X, pred)\n",
    "    print(\"n_estimators = \", n_estimators, \", max_samples=\", max_samples,\", contamination= \",contamination, \", score= \", score)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for n_estimators in [20, 50, 100,300]:\\n    for max_samples in [128, 256, 512]:\\n        for contamination in [0.05, \\'auto\\']:\\n            start = time.time()\\n            #get_score(n_estimators, max_samples,contamination, X=X_train)\\n            F2 = IsolationForest(n_estimators=n_estimators, max_samples=max_samples, contamination=contamination,                         max_features=1.0, bootstrap=False, n_jobs=-1, verbose=0, random_state = 42).fit(data)\\n            em, mv = emmv_scores(F2, data).values()\\n            end = time.time()\\n            print(\"n_estimators: \", n_estimators, \", max_samples: \", max_samples, \", contamination: \", contamination)\\n            print(\"em score: \", em, \", mv score: \", mv)\\n            print(\"Runtime: \", end-start)\\n            print()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for n_estimators in [20, 50, 100,300]:\n",
    "    for max_samples in [128, 256, 512]:\n",
    "        for contamination in [0.05, 'auto']:\n",
    "            start = time.time()\n",
    "            #get_score(n_estimators, max_samples,contamination, X=X_train)\n",
    "            F2 = IsolationForest(n_estimators=n_estimators, max_samples=max_samples, contamination=contamination, \\\n",
    "                        max_features=1.0, bootstrap=False, n_jobs=-1, verbose=0, random_state = 42).fit(data)\n",
    "            em, mv = emmv_scores(F2, data).values()\n",
    "            end = time.time()\n",
    "            print(\"n_estimators: \", n_estimators, \", max_samples: \", max_samples, \", contamination: \", contamination)\n",
    "            print(\"em score: \", em, \", mv score: \", mv)\n",
    "            print(\"Runtime: \", end-start)\n",
    "            print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em score:  0.9873332395396406 , mv score:  0.01007192742996848\n"
     ]
    }
   ],
   "source": [
    "F2 = IsolationForest(n_estimators=100, max_samples=512, contamination=0.02, \\\n",
    "max_features=1.0, bootstrap=False, n_jobs=-1, verbose=0, random_state = 42)\n",
    "F2.fit(data)\n",
    "pred = F2.decision_function(data)\n",
    "pred= F2.predict(data)\n",
    "em, mv = emmv_scores(F2, data).values()\n",
    "print(\"em score: \", em, \", mv score: \", mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['anomaly'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(pd.read_csv(\"y_test_pred\"))[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n",
      "1 -1\n",
      "1 -1\n",
      "-1 -1\n",
      "-1 -1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    if pred[i] == -1:\n",
    "        print(y_test[i], pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918860545210437"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)\n",
    "roc_auc_score(y_test, pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   66,     0],\n",
       "       [  278, 16853]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                             Flow       P_1       P_3       P_4       P_5  \\\n",
      "Datetime                                                                        \n",
      "2021-03-11 10:11:35+00:00   33.302307 -0.026626 -0.016772  0.000457  0.000228   \n",
      "2021-03-11 10:11:36+00:00  -75.946426  0.027433  0.017229  0.000229 -0.000457   \n",
      "2021-03-11 10:12:45+00:00  151.604462  0.008745  0.006432 -0.000457 -0.001296   \n",
      "2021-03-11 10:14:24+00:00   35.671234 -0.000269 -0.000457  0.000914  0.000685   \n",
      "2021-03-11 10:14:26+00:00   51.948166  0.000538  0.000457 -0.000686 -0.000228   \n",
      "...                               ...       ...       ...       ...       ...   \n",
      "2021-03-11 14:56:26+00:00 -236.686796 -0.056572 -0.041996 -0.015293  0.000088   \n",
      "2021-03-11 14:57:13+00:00   36.584473  0.017562  0.016588  0.023439  0.003007   \n",
      "2021-03-11 14:57:14+00:00  -19.727325 -0.016755 -0.015902 -0.024536 -0.002832   \n",
      "2021-03-11 14:58:43+00:00   35.746765  0.055785  0.041857  0.018277 -0.000029   \n",
      "2021-03-11 14:58:44+00:00 -162.539291 -0.056780 -0.041399 -0.015005  0.001803   \n",
      "\n",
      "name                            T_2       T_3       T_4  anomaly  \n",
      "Datetime                                                          \n",
      "2021-03-11 10:11:35+00:00  0.103241  0.087948  0.069018       -1  \n",
      "2021-03-11 10:11:36+00:00 -0.050400 -0.033307 -0.007552       -1  \n",
      "2021-03-11 10:12:45+00:00 -0.007544 -0.080176 -0.072085       -1  \n",
      "2021-03-11 10:14:24+00:00  0.174833  0.166311  0.154174       -1  \n",
      "2021-03-11 10:14:26+00:00 -0.167621 -0.157765 -0.160143       -1  \n",
      "...                             ...       ...       ...      ...  \n",
      "2021-03-11 14:56:26+00:00  2.407790  2.392567  2.400979       -1  \n",
      "2021-03-11 14:57:13+00:00  0.000686  0.006169 -0.004806       -1  \n",
      "2021-03-11 14:57:14+00:00 -0.018399  0.001371 -0.008925       -1  \n",
      "2021-03-11 14:58:43+00:00 -2.289802 -2.273893 -2.271315       -1  \n",
      "2021-03-11 14:58:44+00:00  2.285858  2.260185  2.275434       -1  \n",
      "\n",
      "[344 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[data['anomaly']==-1])\n",
    "\n",
    "anomaly = data[data['anomaly']==-1]\n",
    "anomaly.to_csv(\"anomaly_iso\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dcd4838592ac03288e34d44dab3119b632e2fc48225aca891dd30a5c04d814d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
